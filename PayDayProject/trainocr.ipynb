{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3laOGKltDfY8"
      },
      "source": [
        "Train ocr with keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataseti githubdan çek ve unziple"
      ],
      "metadata": {
        "id": "uvJwJ8AvDuVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "1-V7jS8SDfY9"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/onuralpArsln/toJava/raw/refs/heads/main/PayDayProject/dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dataset.zip"
      ],
      "metadata": {
        "id": "HvZfumkwDrWH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O source.jpg https://raw.githubusercontent.com/onuralpArsln/toJava/main/PayDayProject/source/source.jpg"
      ],
      "metadata": {
        "id": "HFfhEuTdNouy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O source.jpg https://raw.githubusercontent.com/onuralpArsln/toJava/main/PayDayProject/source/test.jpg"
      ],
      "metadata": {
        "id": "tTTjYLwuOWwT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class SpecialLettersOCR:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.class_names = None\n",
        "\n",
        "    def train(self, dataset_path, img_size=(64, 64)):\n",
        "        \"\"\"Train model on single-letter classification dataset\"\"\"\n",
        "        # Load training data\n",
        "        train_path = os.path.join(dataset_path, 'train')\n",
        "        val_path = os.path.join(dataset_path, 'validation')\n",
        "\n",
        "        X_train, y_train, self.class_names = self._load_data(train_path, img_size)\n",
        "        X_val, y_val, _ = self._load_data(val_path, img_size)\n",
        "\n",
        "        # Create and train model\n",
        "        self.model = self._create_model(img_size, len(self.class_names))\n",
        "\n",
        "        self.model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        self.model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=30,\n",
        "            batch_size=32\n",
        "        )\n",
        "\n",
        "        # Save model\n",
        "        self.model.save('special_letters_model.h5')\n",
        "\n",
        "    def _load_data(self, data_path, img_size):\n",
        "        \"\"\"Load and preprocess classification training data\"\"\"\n",
        "        images = []\n",
        "        labels = []\n",
        "        class_names = sorted(os.listdir(data_path))\n",
        "\n",
        "        for idx, class_name in enumerate(class_names):\n",
        "            class_path = os.path.join(data_path, class_name)\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                img = cv2.resize(img, img_size)\n",
        "                img = img / 255.0\n",
        "                images.append(img)\n",
        "                labels.append(idx)\n",
        "\n",
        "        return (np.array(images).reshape(-1, img_size[0], img_size[1], 1),\n",
        "                np.array(labels),\n",
        "                class_names)\n",
        "\n",
        "    def _create_model(self, img_size, num_classes):\n",
        "        \"\"\"Create the CNN model\"\"\"\n",
        "        return models.Sequential([\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 1)),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    def detect_and_recognize(self, image_path):\n",
        "        \"\"\"Detect and recognize multiple letters in a single image\"\"\"\n",
        "        # Load and preprocess image\n",
        "        image = cv2.imread(image_path)\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Binarize image\n",
        "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Sort contours left-to-right\n",
        "        contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
        "\n",
        "        detected_text = \"\"\n",
        "        boxes = []\n",
        "\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            # Filter out noise\n",
        "            if w * h < 100:  # Adjust this threshold based on your images\n",
        "                continue\n",
        "\n",
        "            # Extract letter\n",
        "            letter_img = binary[y:y+h, x:x+w]\n",
        "\n",
        "            # Preprocess for classification\n",
        "            letter_img = cv2.resize(letter_img, (64, 64))\n",
        "            letter_img = letter_img / 255.0\n",
        "            letter_img = letter_img.reshape(1, 64, 64, 1)\n",
        "\n",
        "            # Classify letter\n",
        "            pred = self.model.predict(letter_img, verbose=0)\n",
        "            letter_idx = np.argmax(pred)\n",
        "            confidence = np.max(pred)\n",
        "\n",
        "            if confidence > 0.5:  # Adjust confidence threshold as needed\n",
        "                detected_text += self.class_names[letter_idx]\n",
        "                boxes.append((x, y, w, h))\n",
        "\n",
        "                # Draw bounding box\n",
        "                cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        return detected_text, image, boxes\n",
        "\n",
        "# Usage example\n",
        "def main():\n",
        "    # Initialize OCR\n",
        "    ocr = SpecialLettersOCR()\n",
        "\n",
        "    # Train on your dataset (only need to do this once)\n",
        "    ocr.train(\"dataset\")  # Path to your dataset folder\n",
        "\n",
        "    # OR load pre-trained model if you already trained it\n",
        "    # ocr.model = tf.keras.models.load_model('special_letters_model.h5')\n",
        "    # ocr.class_names = ['your', 'class', 'names']\n",
        "\n",
        "    # Detect and recognize letters in new image\n",
        "    test_image = \"source.jpg\"  # Image with multiple letters\n",
        "    text, annotated_image, boxes = ocr.detect_and_recognize(test_image)\n",
        "\n",
        "    print(f\"Detected text: {text}\")\n",
        "    cv2.imwrite(\"result.jpg\", annotated_image)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDk_vXl6NdRJ",
        "outputId": "e8d875f9-951c-41ff-c46d-58f20c1d5f72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.8394 - loss: 0.4472 - val_accuracy: 0.9700 - val_loss: 0.0801\n",
            "Epoch 2/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9700 - loss: 0.0712 - val_accuracy: 0.9925 - val_loss: 0.0212\n",
            "Epoch 3/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0326 - val_accuracy: 0.9950 - val_loss: 0.0190\n",
            "Epoch 4/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 5/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
            "Epoch 6/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 7/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
            "Epoch 8/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9975 - val_loss: 0.0088\n",
            "Epoch 9/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.6522e-04 - val_accuracy: 0.9975 - val_loss: 0.0038\n",
            "Epoch 10/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6486e-04 - val_accuracy: 0.9975 - val_loss: 0.0042\n",
            "Epoch 11/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4629e-04 - val_accuracy: 0.9975 - val_loss: 0.0041\n",
            "Epoch 12/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4210e-04 - val_accuracy: 0.9975 - val_loss: 0.0046\n",
            "Epoch 13/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.2777e-05 - val_accuracy: 0.9975 - val_loss: 0.0048\n",
            "Epoch 14/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2847e-05 - val_accuracy: 0.9975 - val_loss: 0.0049\n",
            "Epoch 15/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.2719e-05 - val_accuracy: 0.9975 - val_loss: 0.0048\n",
            "Epoch 16/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.6994e-05 - val_accuracy: 0.9975 - val_loss: 0.0051\n",
            "Epoch 17/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.6014e-05 - val_accuracy: 0.9975 - val_loss: 0.0051\n",
            "Epoch 18/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.8596e-05 - val_accuracy: 0.9975 - val_loss: 0.0054\n",
            "Epoch 19/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.8509e-05 - val_accuracy: 0.9975 - val_loss: 0.0051\n",
            "Epoch 20/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.1631e-05 - val_accuracy: 0.9975 - val_loss: 0.0052\n",
            "Epoch 21/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.3136e-05 - val_accuracy: 0.9975 - val_loss: 0.0054\n",
            "Epoch 22/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2287e-05 - val_accuracy: 0.9975 - val_loss: 0.0054\n",
            "Epoch 23/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.1716e-05 - val_accuracy: 0.9975 - val_loss: 0.0053\n",
            "Epoch 24/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.1811e-05 - val_accuracy: 0.9975 - val_loss: 0.0057\n",
            "Epoch 25/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.7921e-05 - val_accuracy: 0.9975 - val_loss: 0.0057\n",
            "Epoch 26/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.5768e-05 - val_accuracy: 0.9975 - val_loss: 0.0057\n",
            "Epoch 27/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.9105e-05 - val_accuracy: 0.9975 - val_loss: 0.0058\n",
            "Epoch 28/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3205e-05 - val_accuracy: 0.9975 - val_loss: 0.0056\n",
            "Epoch 29/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.1105e-05 - val_accuracy: 0.9975 - val_loss: 0.0057\n",
            "Epoch 30/30\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.2549e-06 - val_accuracy: 0.9975 - val_loss: 0.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected text: a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hArNSqZDNdIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O1uGJnaYNdFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DI-GCcGxNdCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NjcJQu0wNc_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "szoMiUpCNc9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JJaX4IMBNc6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e0QvBjQoNc3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mP_BvnviNc04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NUg2mFutNcyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9B35NfipNcv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5cLV_DNbNctF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nz76-lhSNcqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eQtnkwksNcn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VHNi5MJUNclL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yheCNlG8Ncit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K8-VvZCZNcgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import os\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"\n",
        "    Preprocess the input image for character detection\n",
        "    \"\"\"\n",
        "    # Read image\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Binarization\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Noise removal\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    denoised = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    return img, denoised\n",
        "\n",
        "def detect_characters(binary_image):\n",
        "    \"\"\"\n",
        "    Detect individual characters in the binary image\n",
        "    Returns list of bounding boxes (x, y, w, h)\n",
        "    \"\"\"\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Filter and sort contours\n",
        "    char_boxes = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        # Filter out noise (adjust these thresholds based on your images)\n",
        "        if w * h > 100 and w/h < 3 and h/w < 3:\n",
        "            char_boxes.append((x, y, w, h))\n",
        "\n",
        "    # Sort characters left to right\n",
        "    char_boxes.sort(key=lambda box: box[0])\n",
        "\n",
        "    return char_boxes\n",
        "\n",
        "def extract_character(image, box, target_size=(64, 64)):\n",
        "    \"\"\"\n",
        "    Extract and preprocess a single character from the image\n",
        "    \"\"\"\n",
        "    x, y, w, h = box\n",
        "    char_img = image[y:y+h, x:x+w]\n",
        "\n",
        "    # Add padding to make it square\n",
        "    height, width = char_img.shape\n",
        "    max_dim = max(height, width)\n",
        "    pad_vert = (max_dim - height) // 2\n",
        "    pad_horz = (max_dim - width) // 2\n",
        "\n",
        "    char_img = cv2.copyMakeBorder(\n",
        "        char_img,\n",
        "        pad_vert,\n",
        "        pad_vert + (max_dim - height) % 2,\n",
        "        pad_horz,\n",
        "        pad_horz + (max_dim - width) % 2,\n",
        "        cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    )\n",
        "\n",
        "    # Resize to target size\n",
        "    char_img = cv2.resize(char_img, target_size)\n",
        "\n",
        "    # Normalize\n",
        "    char_img = char_img / 255.0\n",
        "\n",
        "    return char_img\n",
        "\n",
        "class MultiCharacterOCR:\n",
        "    def __init__(self, model_path, class_names):\n",
        "        self.model = tf.keras.models.load_model(model_path)\n",
        "        self.class_names = class_names\n",
        "\n",
        "    def predict_string(self, image_path):\n",
        "        \"\"\"\n",
        "        Detect and classify all characters in an image\n",
        "        Returns the predicted string and character confidences\n",
        "        \"\"\"\n",
        "        # Preprocess image\n",
        "        original_img, binary_img = preprocess_image(image_path)\n",
        "\n",
        "        # Detect character regions\n",
        "        char_boxes = detect_characters(binary_img)\n",
        "\n",
        "        # Extract and classify each character\n",
        "        predicted_string = \"\"\n",
        "        confidences = []\n",
        "\n",
        "        for box in char_boxes:\n",
        "            # Extract character\n",
        "            char_img = extract_character(binary_img, box)\n",
        "            char_img = char_img.reshape(1, 64, 64, 1)  # Adjust shape based on your model\n",
        "\n",
        "            # Predict\n",
        "            pred = self.model.predict(char_img, verbose=0)\n",
        "            char_idx = np.argmax(pred)\n",
        "            confidence = np.max(pred)\n",
        "\n",
        "            predicted_string += self.class_names[char_idx]\n",
        "            confidences.append(confidence)\n",
        "\n",
        "            # Draw bounding box (for visualization)\n",
        "            x, y, w, h = box\n",
        "            cv2.rectangle(original_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        return predicted_string, confidences, original_img\n",
        "\n",
        "# Example usage:\n",
        "def main():\n",
        "    # Load your trained classification model and class names\n",
        "    model_path = \"path/to/your/trained_model.h5\"\n",
        "    class_names = [\"your\", \"character\", \"classes\"]  # Replace with your actual classes\n",
        "\n",
        "    # Initialize OCR\n",
        "    ocr = MultiCharacterOCR(model_path, class_names)\n",
        "\n",
        "    # Process an image\n",
        "    image_path = \"path/to/test_image.jpg\"\n",
        "    predicted_text, confidences, annotated_img = ocr.predict_string(image_path)\n",
        "\n",
        "    print(f\"Predicted text: {predicted_text}\")\n",
        "    print(f\"Character confidences: {confidences}\")\n",
        "\n",
        "    # Save or display the annotated image\n",
        "    cv2.imwrite(\"annotated_result.jpg\", annotated_img)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "MjZMOB5FKwYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train için idinrimeler ve importları yap"
      ],
      "metadata": {
        "id": "I1ECfh4_DyEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rb_uFgeRJBpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-rTEoQP8JBmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jk0YmWraJBiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YdswsIcsJBfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-a6ehb_tJBcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0YpLIxc6JBaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_RD9iTKoJBX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zowKbgfZJBVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pANM95k-JBS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5npLh4JzJBQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PdEVwI7OJBNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tYbklq2yJBLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gq-Fisy9JBIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-DpcfBldJBF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aVqeD7XzJBDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eFyHTq9cJBA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DUwDdKPJJA-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9cLug3BlJA7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K4Q2fPuyJA49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1J7A26kRJA2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tSxZfS2vJAzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dMd2wNzJJAxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "crctIAECJAuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mQZC7689JAsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4uL4KfVxJApn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h5HOVEaFJAmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr\n",
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2ogs3PtG6FE",
        "outputId": "d2bcc102-1afc-405a-cf61-12b97232a625"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.20.1+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr) (11.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.1)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->easyocr)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->easyocr)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->easyocr)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->easyocr)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->easyocr)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->easyocr)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.1.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.6/286.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyclipper-1.3.0.post6 python-bidi-0.6.3\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "vSsyssRpG9Do"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomOCRDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        for label, letter in enumerate(os.listdir(root_dir)):\n",
        "            letter_path = os.path.join(root_dir, letter)\n",
        "            for img in os.listdir(letter_path):\n",
        "                self.image_paths.append(os.path.join(letter_path, img))\n",
        "                self.labels.append(letter)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        from PIL import Image\n",
        "        image = Image.open(self.image_paths[idx]).convert('L')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "Rd2J9wAgHBTK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomOCRDataset(root_dir='dataset/train', transform=transform)\n",
        "val_dataset = CustomOCRDataset(root_dir='dataset/validation', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "mSs-36ihHVmh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from easyocr.model import Model\n",
        "\n",
        "custom_characters = ['letter1', 'letter2', 'letter3', 'letter4']\n",
        "reader = easyocr.Reader([], gpu=torch.cuda.is_available(), character_list=custom_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ramRIQNQHnQa",
        "outputId": "6085f6e7-e572-487b-d0eb-c2d4651bf331"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Model' from 'easyocr.model' (/usr/local/lib/python3.11/dist-packages/easyocr/model/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-4a2dae812a86>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0measyocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcustom_characters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'letter1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'letter2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'letter3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'letter4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0measyocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_characters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Model' from 'easyocr.model' (/usr/local/lib/python3.11/dist-packages/easyocr/model/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_dataset = CustomOCRDataset(root_dir='/dataset/train', transform=transform)\n",
        "val_dataset = CustomOCRDataset(root_dir='/dataset/validation', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "9E87ehesHVIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = 'source.jpg'\n",
        "results = reader.readtext(image_path)\n",
        "for (bbox, text, prob) in results:\n",
        "    print(f'Text: {text}, Confidence: {prob:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV6MN6wJHzIr",
        "outputId": "10dec5e6-67e3-42db-f258-572ca7777f91"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 6 6 0 I 0*8' & Av XX } 1 * 1>)1X € | b H: H 0 J6, Confidence: 0.0145\n",
            "Text: 1 B C 0 E } 6 H I j K L m n 0 P Q R $ T U V W X Y 2, Confidence: 0.0859\n",
            "Text: 8 F F: E E: > WE % HH Q, Confidence: 0.0866\n",
            "Text: :0 \" |, Confidence: 0.3795\n",
            "Text: f & € & 0.0 *8, Confidence: 0.2087\n",
            "Text: 0 | 2 3 4 5 6 7 9 9, Confidence: 0.2763\n",
            "Text: (Period, degree, Minute; Second), Confidence: 0.5829\n",
            "Text: Unknolvn, Confidence: 0.5048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rdXY169THFsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Bjlcbz1lHFnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GawsJLDfHFen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tensorflow opencv-python matplotlib\n"
      ],
      "metadata": {
        "id": "fmJ6-sGDDxmg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "rmkDhzT0D6zb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "img_width, img_height = 32, 32\n",
        "batch_size = 32\n",
        "epochs = 15  # Increase if you have a larger dataset\n",
        "train_data_dir = 'dataset/train'\n",
        "validation_data_dir = 'dataset/validation'\n",
        "num_classes = len(os.listdir(train_data_dir))  # Assuming one folder per class\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Only rescaling for validation data\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    color_mode='grayscale',  # set to \"rgb\" if your images are colored\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Build CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Save the model for later use\n",
        "model.save('custom_ocr_model.h5')\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IflmgXWrECJd",
        "outputId": "cf26f13c-d416-4bd2-bd2f-e45d2468a93e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m295,040\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m314,372\u001b[0m (1.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314,372</span> (1.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m314,372\u001b[0m (1.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314,372</span> (1.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.8029 - loss: 0.6294 - val_accuracy: 0.9479 - val_loss: 0.1355\n",
            "Epoch 2/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.9385 - loss: 0.1429 - val_accuracy: 0.9661 - val_loss: 0.0747\n",
            "Epoch 3/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.9722 - loss: 0.0737 - val_accuracy: 0.9870 - val_loss: 0.0554\n",
            "Epoch 4/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9773 - loss: 0.0621 - val_accuracy: 0.9870 - val_loss: 0.0328\n",
            "Epoch 5/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - accuracy: 0.9832 - loss: 0.0503 - val_accuracy: 0.9896 - val_loss: 0.0255\n",
            "Epoch 6/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9870 - loss: 0.0394 - val_accuracy: 0.9974 - val_loss: 0.0116\n",
            "Epoch 7/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9887 - loss: 0.0364 - val_accuracy: 0.9922 - val_loss: 0.0249\n",
            "Epoch 8/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.9880 - loss: 0.0403 - val_accuracy: 0.9974 - val_loss: 0.0117\n",
            "Epoch 9/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.9927 - loss: 0.0215 - val_accuracy: 0.9974 - val_loss: 0.0080\n",
            "Epoch 10/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.9889 - loss: 0.0239 - val_accuracy: 0.9948 - val_loss: 0.0121\n",
            "Epoch 11/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.9958 - loss: 0.0158 - val_accuracy: 0.9974 - val_loss: 0.0048\n",
            "Epoch 12/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - accuracy: 0.9956 - loss: 0.0185 - val_accuracy: 0.9974 - val_loss: 0.0054\n",
            "Epoch 13/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.9969 - loss: 0.0161 - val_accuracy: 0.9948 - val_loss: 0.0087\n",
            "Epoch 14/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.9936 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 15/15\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9963 - loss: 0.0105 - val_accuracy: 0.9974 - val_loss: 0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".h5 dosyasını indirdikten sonra başka yerlerde kullanman mümkün\n"
      ],
      "metadata": {
        "id": "FvcRmE9KELuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -1 -O source.jpg https://raw.githubusercontent.com/onuralpArsln/toJava/main/PayDayProject/source/source.jpg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpVLwo6WEPY6",
        "outputId": "f1bb9b22-5dfe-4804-d719-b0c58a4147b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-02 14:31:00--  https://raw.githubusercontent.com/onuralpArsln/toJava/main/PayDayProject/source/source.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47486 (46K) [image/jpeg]\n",
            "Saving to: ‘source.jpg’\n",
            "\n",
            "source.jpg          100%[===================>]  46.37K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-02-02 14:31:00 (2.54 MB/s) - ‘source.jpg’ saved [47486/47486]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use your model"
      ],
      "metadata": {
        "id": "rUT_BL0mEojL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load your trained OCR model\n",
        "model = load_model('/content/custom_ocr_model.h5')  # Update with your model path\n",
        "\n",
        "# Define image preprocessing function\n",
        "def preprocess_image(img):\n",
        "    img = cv2.resize(img, (28, 28))  # Resize to match model input\n",
        "    img = img.astype('float32') / 255.0  # Normalize\n",
        "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    return img\n",
        "\n",
        "# Load and preprocess the main image\n",
        "image_path = '/content/source.jpg'  # Update with your image path\n",
        "original_img = cv2.imread(image_path)\n",
        "gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
        "_, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Find contours (detected letters)\n",
        "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Reverse class index dictionary\n",
        "class_indices = {'A': 0, 'B': 1, 'C': 2}  # Adjust based on training data\n",
        "labels = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "# Loop through detected letters\n",
        "for cnt in contours:\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "    # Extract and preprocess letter\n",
        "    letter_img = gray[y:y+h, x:x+w]\n",
        "    letter_img = preprocess_image(letter_img)\n",
        "\n",
        "    # Predict letter\n",
        "    pred = model.predict(letter_img)\n",
        "    predicted_class = np.argmax(pred, axis=1)[0]\n",
        "    predicted_letter = labels[predicted_class]\n",
        "\n",
        "    # Draw bounding box and label\n",
        "    cv2.rectangle(original_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    cv2.putText(original_img, predicted_letter, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "# Convert BGR to RGB for Matplotlib\n",
        "rgb_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display image in Colab\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(rgb_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Save result\n",
        "cv2.imwrite(\"/content/output_marked.png\", original_img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "oqxYkKtEEoD0",
        "outputId": "5a0cf00d-67b5-4e31-8f91-bd21de44ba80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2304, but received input with shape (1, 1600)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 28, 28, 1), dtype=float32)\n  • training=False\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8005bb194a0a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Predict letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mpredicted_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 }:\n\u001b[0;32m--> 227\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2304, but received input with shape (1, 1600)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 28, 28, 1), dtype=float32)\n  • training=False\n  • mask=None"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}